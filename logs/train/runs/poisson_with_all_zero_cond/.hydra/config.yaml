task_name: train
tags:
- xy
- simple_pinn
train: true
test: false
ckpt_path: null
seed: 12345
conditional_loss: val/loss
data:
  _recursive_: false
  _target_: src.data.lightning_data_module.LitDataModule
  dataset:
    _target_: src.data.components.dataset.DatasetXY
    n_samples: 50000
    xmin: 0
    xmax: 1
    ymin: 0
    ymax: 1
  collator:
    _target_: src.data.components.collate.BaseCollator
    with_coords: true
    with_time: false
  train_batch_size: 64
  val_batch_size: 64
  pin_memory: true
  num_workers: 0
  persistent_workers: false
model:
  _target_: src.models.pde_lit_model_xy.PDELitModule
  _recursive_: true
  conditional_loss: ${conditional_loss}
  train_batch_size: ${data.train_batch_size}
  val_batch_size: ${data.val_batch_size}
  optimizer:
    _target_: torch.optim.Adam
    _partial_: true
    lr: 0.001
    weight_decay: 1.0e-06
  scheduler:
    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
    _partial_: true
    mode: max
    factor: 0.1
    patience: 2
  alpha: 1
  beta: 1
  pdec:
    _target_: src.models.components.utils.conditions.PDEXYConditions
  ic:
    _target_: src.models.components.utils.conditions.InitialConditions
  bc:
    _target_: src.models.components.utils.conditions.BoundaryXYConditions
  net:
    _target_: src.models.components.pde_nn.PDESimpleNN
    embedding_dim: 8
    coords_layers:
    - _target_: src.models.components.encoders.coords_encoder.CoordsEncoderLayer
      num_coords: 2
      embedding_dim: ${model.net.embedding_dim}
      dropout_inputs: 0.0
    time_layers:
    - _target_: src.models.components.encoders.time_encoder.TimeEncoderLayer
      embedding_dim: ${model.net.embedding_dim}
      dropout_inputs: 0.0
    main_encoder:
      _target_: src.models.components.encoders.main_sequence_encoder.MainEncoderLayer
      input_size: ${model.net.embedding_dim}
      embedding_dim: ${model.net.embedding_dim}
      dropout_inputs: 0.1
    main_layers:
    - _target_: src.models.components.linear_blocks.linear_down_up_block.LinearDownUpBlock
      down: true
      in_features: ${model.net.embedding_dim}
      out_features: 1
      activation_type: tanh
      num_layers: 2
      use_batch_norm: true
  compile: false
trainer:
  _target_: lightning.pytorch.trainer.Trainer
  default_root_dir: ${paths.output_dir}
  min_epochs: 1
  max_epochs: 3
  accelerator: cpu
  devices: 1
  check_val_every_n_epoch: 1
  deterministic: false
  precision: bf16-mixed
  log_every_n_steps: 10
  gradient_clip_val: 0.5
logger:
  tensorboard:
    _target_: lightning.pytorch.loggers.tensorboard.TensorBoardLogger
    save_dir: ${paths.output_dir}/tensorboard/
    name: null
    log_graph: false
    default_hp_metric: true
    prefix: ''
callbacks:
  model_checkpoint:
    _target_: lightning.pytorch.callbacks.ModelCheckpoint
    dirpath: ${paths.output_dir}/checkpoints
    filename: epoch_{epoch:03d}
    monitor: ${conditional_loss}
    verbose: false
    save_last: true
    save_top_k: 1
    mode: max
    auto_insert_metric_name: false
    save_weights_only: false
    every_n_train_steps: null
    train_time_interval: null
    every_n_epochs: null
    save_on_train_epoch_end: null
  early_stopping:
    _target_: lightning.pytorch.callbacks.EarlyStopping
    monitor: ${conditional_loss}
    min_delta: 0.0
    patience: 5
    verbose: false
    mode: max
    strict: true
    check_finite: true
    stopping_threshold: null
    divergence_threshold: null
    check_on_train_epoch_end: null
  model_summary:
    _target_: lightning.pytorch.callbacks.RichModelSummary
    max_depth: -1
  rich_progress_bar:
    _target_: lightning.pytorch.callbacks.RichProgressBar
  lr_monitor:
    _target_: lightning.pytorch.callbacks.LearningRateMonitor
    logging_interval: epoch
    log_momentum: true
paths:
  root_dir: ${oc.env:PROJECT_ROOT}
  data_dir: ${paths.root_dir}/data/coords_xy
  log_dir: ${paths.root_dir}/logs/
  output_dir: ${hydra:runtime.output_dir}
  work_dir: ${hydra:runtime.cwd}
