task_name: train
tags:
- xt
- simple_pinn
train: true
test: false
ckpt_path: null
seed: 12345
conditional_loss: train/loss
data:
  _recursive_: false
  _target_: src.data.lightning_data_module.LitDataModule
  dataset:
    _target_: src.data.components.dataset.SpatialXTemporalDomain
    n_samples: 100000
    xmin: -5
    xmax: 5
    tmin: 0
    tmax: 10
    noise: 0.0001
  collator:
    _target_: src.data.components.collate.BaseCollator
    with_coords: true
    with_time: true
  train_batch_size: 128
  val_batch_size: 128
  pin_memory: true
  num_workers: 0
  persistent_workers: false
model:
  _target_: src.models.pde_lit_model_xt.PDELitModule
  _recursive_: true
  conditional_loss: ${conditional_loss}
  train_batch_size: ${data.train_batch_size}
  val_batch_size: ${data.val_batch_size}
  optimizer:
    _target_: torch.optim.Adam
    _partial_: true
    lr: 0.001
    weight_decay: 0.0001
  scheduler:
    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
    _partial_: true
    mode: min
    factor: 0.1
    patience: 2
  alpha: 1.0
  beta: 1.0
  nu: 0.5
  num_coords: 1
  bc_limits:
  - ${data.dataset.xmin}
  - ${data.dataset.xmax}
  condition_names:
  - pdec
  - ic
  - bc_lower
  - bc_upper
  conditions:
    pdec:
      _target_: src.models.components.utils.conditions.PDEBurgerCondition
    ic:
    - _target_: src.models.components.utils.conditions.InitialConditions
    bc:
    - _target_: src.models.components.utils.conditions.BoundaryXYZConditions
    - _target_: src.models.components.utils.conditions.BoundaryXYZConditions
  net:
    _target_: src.models.components.pde_nn.PDESimpleNN
    embedding_dim: 16
    layers:
    - _target_: src.models.components.encoders.main_sequence_encoder.MainEncoderLayer
      embedding_sequence_dim: ${model.net.embedding_dim}
      embedding_features_dim: 0
      dropout_inputs: 0.1
      num_coords: 1
      with_time: ${data.collator.with_time}
    - _target_: src.models.components.linear_blocks.linear_down_up_block.LinearDownUpBlock
      down: true
      in_features: ${eval:${model.net.embedding_dim} * 2}
      out_features: 1
      activation_type: tanh
      num_layers: 2
      use_batch_norm: false
  compile: false
trainer:
  _target_: lightning.pytorch.trainer.Trainer
  default_root_dir: ${paths.output_dir}
  min_epochs: 1
  max_epochs: 3
  accelerator: cpu
  devices: 1
  check_val_every_n_epoch: 1
  deterministic: false
  precision: bf16-mixed
  log_every_n_steps: 30
  gradient_clip_val: 0.5
logger:
  tensorboard:
    _target_: lightning.pytorch.loggers.tensorboard.TensorBoardLogger
    save_dir: ${paths.output_dir}/tensorboard/
    name: null
    log_graph: false
    default_hp_metric: true
    prefix: ''
callbacks:
  model_checkpoint:
    _target_: lightning.pytorch.callbacks.ModelCheckpoint
    dirpath: ${paths.output_dir}/checkpoints
    filename: epoch_{epoch:03d}
    monitor: ${conditional_loss}
    verbose: false
    save_last: true
    save_top_k: 1
    mode: min
    auto_insert_metric_name: false
    save_weights_only: false
    every_n_train_steps: null
    train_time_interval: null
    every_n_epochs: null
    save_on_train_epoch_end: null
  early_stopping:
    _target_: lightning.pytorch.callbacks.EarlyStopping
    monitor: ${conditional_loss}
    min_delta: 0.0
    patience: 3
    verbose: false
    mode: min
    strict: true
    check_finite: true
    stopping_threshold: null
    divergence_threshold: null
    check_on_train_epoch_end: null
  model_summary:
    _target_: lightning.pytorch.callbacks.RichModelSummary
    max_depth: -1
  rich_progress_bar:
    _target_: lightning.pytorch.callbacks.RichProgressBar
  lr_monitor:
    _target_: lightning.pytorch.callbacks.LearningRateMonitor
    logging_interval: epoch
    log_momentum: true
paths:
  root_dir: ${oc.env:PROJECT_ROOT}
  data_dir: ${paths.root_dir}/data/coords_xy
  log_dir: ${paths.root_dir}/logs/
  output_dir: ${hydra:runtime.output_dir}
  work_dir: ${hydra:runtime.cwd}
