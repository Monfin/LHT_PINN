# @package _global_

# to execute this experiment run:
# python train.py +experiment=example

# defaults:
#   - override /data: credits_history_dataset.yaml
#   - override /model: embeddings_gru_pooling.yaml
#   - override /trainer: cpu.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["xy", "simple_pinn"]

seed: 12345

# set data params
data:

  dataset: 
    _target_: src.data.components.dataset.DatasetXY

    n_samples: 100_000

    xmin: -1000
    xmax: 1000

    ymin: -1000
    ymax: 1000

  collator:
    _target_: src.data.components.collate.BaseCollator
    with_coords: True
    with_time: False

  train_batch_size: 128
  val_batch_size: 128


# set trainer params
trainer:
  accelerator: cpu

  min_epochs: 1 # prevents early stopping
  max_epochs: 5

  devices: 1

  # mixed precision for extra speed-up
  precision: bf16-mixed

  log_every_n_steps: 30


# set model params
model:
  _target_: src.models.pde_lit_model_xy.PDELitModule
  _recursive_: True

  train_batch_size: ${data.train_batch_size}
  val_batch_size: ${data.val_batch_size}

  conditional_loss: ${conditional_loss}

  optimizer: 
    _target_: torch.optim.Adam
    _partial_: True
    lr: 1.0e-3
    weight_decay: 1.0e-6

  scheduler:
    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
    _partial_: True
    mode: min
    factor: 0.1 # new_lr = factor & old_lr
    patience: 2

  alpha: 1.0
  beta: 1.0

  condition_names:
    - pdec 
    - bc_x
    - bc_y

  pdec: 
    _target_: src.models.components.utils.conditions.PDEXYConditions
  
  ic: null

  num_coords: 2
  bc:
    _target_: src.models.components.utils.conditions.BoundaryXYConditions

  net:
    _target_: src.models.components.pde_nn.PDESimpleNN
    embedding_dim: 32


    ### Coords layers
    coords_layers:
      ### Encoder layer for coord components
      - _target_: src.models.components.encoders.coords_encoder.CoordsEncoderLayer

        num_coords: 2

        embedding_dim: ${model.net.embedding_dim}

        dropout_inputs: 0.0


    time_layers: []
    

    ### Main Encoder layer
    main_encoder:
      _target_: src.models.components.encoders.main_sequence_encoder.MainEncoderLayer

      embedding_dim: ${model.net.embedding_dim}

      dropout_inputs: 0.1


    ### Main layers (merged components)
    main_layers:

      ### Simple attention 1d
      - _target_: src.models.components.attention.simple_attention_1d.SimpleAttention1d

        features_dim: ${model.net.embedding_dim}

        use_batch_norm: False


      ### Down Linear Block
      - _target_: src.models.components.linear_blocks.linear_down_up_block.LinearDownUpBlock

        down: True

        in_features: ${model.net.embedding_dim}
        out_features: 1
        activation_type: tanh

        num_layers: 2
        use_batch_norm: False