{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from IPython.display import display as d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from typing import Optional, List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.components.dataset import SpatialTemporalDomain\n",
    "from abc import ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "COORDS_LIMITS = {\"x\": [-3, 3]}\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SpatialTemporalDomain(coords_limits=COORDS_LIMITS, time_limits=[0, 100], n_samples=200_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_coords = namedtuple(typename=\"coords\", field_names=[\"x\", \"y\", \"z\"])\n",
    "class Coords(_coords):\n",
    "    x: torch.Tensor\n",
    "    y: torch.Tensor\n",
    "    z: torch.Tensor\n",
    "\n",
    "    def __new__(\n",
    "        cls, \n",
    "        x: Optional[torch.Tensor] = torch.tensor([]),\n",
    "        y: Optional[torch.Tensor] = torch.tensor([]),\n",
    "        z: Optional[torch.Tensor] = torch.tensor([])\n",
    "    ):\n",
    "        return super().__new__(cls, x=x, y=y, z=z)\n",
    "\n",
    "\n",
    "_model_input = namedtuple(typename=\"STD\", field_names=[\"coords\", \"time\"])\n",
    "class ModelBatch(_model_input):\n",
    "    coords: Coords\n",
    "    time: Optional[torch.Tensor]\n",
    "\n",
    "    def __new__(\n",
    "        cls,\n",
    "        coords: Coords = Coords(),\n",
    "        time: Optional[torch.Tensor] = torch.tensor([])\n",
    "    ):\n",
    "        return super().__new__(cls, coords=coords, time=time)\n",
    "    \n",
    "\n",
    "_model_output = namedtuple(typename=\"SpatialTemporalDomainSolution\", field_names=[\"model_batch\", \"solution\"])\n",
    "class ModelOutput(_model_output):\n",
    "    model_batch: ModelBatch\n",
    "    solution: torch.Tensor\n",
    "\n",
    "    def __new__(\n",
    "        cls,\n",
    "        model_batch: ModelBatch = ModelBatch(),\n",
    "        solution: torch.Tensor = torch.tensor([])\n",
    "    ):\n",
    "        return super().__new__(cls, model_batch=model_batch, solution=solution)\n",
    "\n",
    "class Collator(ABC):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, batch: List[Dict]) -> ModelBatch:\n",
    "        pass\n",
    "\n",
    "\n",
    "class BaseCollator(Collator):\n",
    "    def __call__(self, batch: List[Dict]) -> ModelBatch:\n",
    "        coords = dict()\n",
    "\n",
    "        _item = batch[0]\n",
    "\n",
    "        for key in _item[\"coords\"].keys():\n",
    "            coords[key] = torch.stack([item[\"coords\"][key] for item in batch], dim=0)\n",
    "            coords[key].requires_grad_(True)\n",
    "\n",
    "\n",
    "        if _item[\"time\"].__len__() > 0:\n",
    "            time = torch.stack([item[\"time\"] for item in batch], dim=0)\n",
    "            time.requires_grad_(True)\n",
    "        else:\n",
    "            time = torch.tensor([])\n",
    "\n",
    "        return ModelBatch(\n",
    "            coords=Coords(**coords), \n",
    "            time=time\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    collate_fn=BaseCollator()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.components.encoders.main_sequence_encoder import MainEncoderLayer\n",
    "from src.models.components.linear_blocks.linear_down_up_block import LinearDownUpBlock\n",
    "from src.models.components.pde_nn import SimplePINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.partial_checkpoint import PartialCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_PATH = \"logs/train/runs/2024-08-07_00-22-42/checkpoints/epoch_009.ckpt\"\n",
    "EMB_DIM = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PartialCheckpoint(\n",
       "  (partial_model): MainEncoderLayer(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (branched_linear_block_xyz): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=32, bias=True)\n",
       "        (1): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (linear_block_t): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=32, bias=True)\n",
       "      (1): Tanh()\n",
       "    )\n",
       "    (out_linear_block): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (res_bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "partial_enc = PartialCheckpoint(\n",
    "    target_model=MainEncoderLayer(\n",
    "        embedding_dim=EMB_DIM, \n",
    "        dropout_inputs=0.0, \n",
    "        num_coords=1\n",
    "    ),\n",
    "    ckpt_path=CKPT_PATH,\n",
    "    ckpt_prefix=\"net._orig_mod.layers.0\"\n",
    ")\n",
    "d(partial_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PartialCheckpoint(\n",
       "  (partial_model): LinearDownUpBlock(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (linear_block): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Tanh()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (out_block): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (cls_layers): Sequential(\n",
       "      (0): Dropout(p=0.0, inplace=False)\n",
       "      (1): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Tanh()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Tanh()\n",
       "        )\n",
       "      )\n",
       "      (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "partial_linear = PartialCheckpoint(\n",
    "    target_model=LinearDownUpBlock(\n",
    "        in_features=EMB_DIM, \n",
    "        out_features=1, \n",
    "        activation_type=\"tanh\", \n",
    "        reduce=False, \n",
    "        down=True, \n",
    "        num_layers=2, \n",
    "        use_batch_norm=True\n",
    "    ),\n",
    "    ckpt_path=CKPT_PATH,\n",
    "    ckpt_prefix=\"net._orig_mod.layers.1\"\n",
    ")\n",
    "d(partial_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TracedSimplePINN(SimplePINN):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(TracedSimplePINN, self).__init__(**kwargs)\n",
    "\n",
    "\n",
    "    def forward(self, coords: Coords, time: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        inputs = ModelBatch(coords, time)\n",
    "\n",
    "        return super().forward(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TracedSimplePINN(\n",
       "  (layers): Sequential(\n",
       "    (0): PartialCheckpoint(\n",
       "      (partial_model): MainEncoderLayer(\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (branched_linear_block_xyz): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=1, out_features=32, bias=True)\n",
       "            (1): Tanh()\n",
       "          )\n",
       "        )\n",
       "        (linear_block_t): Sequential(\n",
       "          (0): Linear(in_features=4, out_features=32, bias=True)\n",
       "          (1): Tanh()\n",
       "        )\n",
       "        (out_linear_block): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (res_bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): PartialCheckpoint(\n",
       "      (partial_model): LinearDownUpBlock(\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear_block): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Tanh()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Tanh()\n",
       "          )\n",
       "        )\n",
       "        (out_block): Linear(in_features=32, out_features=1, bias=True)\n",
       "        (cls_layers): Sequential(\n",
       "          (0): Dropout(p=0.0, inplace=False)\n",
       "          (1): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Tanh()\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): Tanh()\n",
       "            )\n",
       "          )\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "partial_model = TracedSimplePINN(layers=[partial_enc, partial_linear], embedding_dim=32)\n",
    "d(partial_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TracedSimplePINN(\n",
       "  original_name=TracedSimplePINN\n",
       "  (layers): Sequential(\n",
       "    original_name=Sequential\n",
       "    (0): PartialCheckpoint(\n",
       "      original_name=PartialCheckpoint\n",
       "      (partial_model): MainEncoderLayer(\n",
       "        original_name=MainEncoderLayer\n",
       "        (dropout): Dropout(original_name=Dropout)\n",
       "        (branched_linear_block_xyz): ModuleList(\n",
       "          original_name=ModuleList\n",
       "          (0): Sequential(\n",
       "            original_name=Sequential\n",
       "            (0): Linear(original_name=Linear)\n",
       "            (1): Tanh(original_name=Tanh)\n",
       "          )\n",
       "        )\n",
       "        (linear_block_t): Sequential(\n",
       "          original_name=Sequential\n",
       "          (0): Linear(original_name=Linear)\n",
       "          (1): Tanh(original_name=Tanh)\n",
       "        )\n",
       "        (out_linear_block): Sequential(\n",
       "          original_name=Sequential\n",
       "          (0): Linear(original_name=Linear)\n",
       "          (1): BatchNorm1d(original_name=BatchNorm1d)\n",
       "        )\n",
       "        (res_bn): BatchNorm1d(original_name=BatchNorm1d)\n",
       "      )\n",
       "    )\n",
       "    (1): PartialCheckpoint(\n",
       "      original_name=PartialCheckpoint\n",
       "      (partial_model): LinearDownUpBlock(\n",
       "        original_name=LinearDownUpBlock\n",
       "        (dropout): Dropout(original_name=Dropout)\n",
       "        (linear_block): Sequential(\n",
       "          original_name=Sequential\n",
       "          (0): Sequential(\n",
       "            original_name=Sequential\n",
       "            (0): Linear(original_name=Linear)\n",
       "            (1): BatchNorm1d(original_name=BatchNorm1d)\n",
       "            (2): Tanh(original_name=Tanh)\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            original_name=Sequential\n",
       "            (0): Linear(original_name=Linear)\n",
       "            (1): BatchNorm1d(original_name=BatchNorm1d)\n",
       "            (2): Tanh(original_name=Tanh)\n",
       "          )\n",
       "        )\n",
       "        (out_block): Linear(original_name=Linear)\n",
       "        (cls_layers): Sequential(\n",
       "          original_name=Sequential\n",
       "          (0): Dropout(original_name=Dropout)\n",
       "          (1): Sequential(\n",
       "            original_name=Sequential\n",
       "            (0): Sequential(\n",
       "              original_name=Sequential\n",
       "              (0): Linear(original_name=Linear)\n",
       "              (1): BatchNorm1d(original_name=BatchNorm1d)\n",
       "              (2): Tanh(original_name=Tanh)\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              original_name=Sequential\n",
       "              (0): Linear(original_name=Linear)\n",
       "              (1): BatchNorm1d(original_name=BatchNorm1d)\n",
       "              (2): Tanh(original_name=Tanh)\n",
       "            )\n",
       "          )\n",
       "          (2): Linear(original_name=Linear)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "traced_partial_model = torch.jit.trace(partial_model, sample)\n",
    "d(traced_partial_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OptimizedModule(\n",
       "  (_orig_mod): TracedSimplePINN(\n",
       "    original_name=TracedSimplePINN\n",
       "    (layers): Sequential(\n",
       "      original_name=Sequential\n",
       "      (0): PartialCheckpoint(\n",
       "        original_name=PartialCheckpoint\n",
       "        (partial_model): MainEncoderLayer(\n",
       "          original_name=MainEncoderLayer\n",
       "          (dropout): Dropout(original_name=Dropout)\n",
       "          (branched_linear_block_xyz): ModuleList(\n",
       "            original_name=ModuleList\n",
       "            (0): Sequential(\n",
       "              original_name=Sequential\n",
       "              (0): Linear(original_name=Linear)\n",
       "              (1): Tanh(original_name=Tanh)\n",
       "            )\n",
       "          )\n",
       "          (linear_block_t): Sequential(\n",
       "            original_name=Sequential\n",
       "            (0): Linear(original_name=Linear)\n",
       "            (1): Tanh(original_name=Tanh)\n",
       "          )\n",
       "          (out_linear_block): Sequential(\n",
       "            original_name=Sequential\n",
       "            (0): Linear(original_name=Linear)\n",
       "            (1): BatchNorm1d(original_name=BatchNorm1d)\n",
       "          )\n",
       "          (res_bn): BatchNorm1d(original_name=BatchNorm1d)\n",
       "        )\n",
       "      )\n",
       "      (1): PartialCheckpoint(\n",
       "        original_name=PartialCheckpoint\n",
       "        (partial_model): LinearDownUpBlock(\n",
       "          original_name=LinearDownUpBlock\n",
       "          (dropout): Dropout(original_name=Dropout)\n",
       "          (linear_block): Sequential(\n",
       "            original_name=Sequential\n",
       "            (0): Sequential(\n",
       "              original_name=Sequential\n",
       "              (0): Linear(original_name=Linear)\n",
       "              (1): BatchNorm1d(original_name=BatchNorm1d)\n",
       "              (2): Tanh(original_name=Tanh)\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              original_name=Sequential\n",
       "              (0): Linear(original_name=Linear)\n",
       "              (1): BatchNorm1d(original_name=BatchNorm1d)\n",
       "              (2): Tanh(original_name=Tanh)\n",
       "            )\n",
       "          )\n",
       "          (out_block): Linear(original_name=Linear)\n",
       "          (cls_layers): Sequential(\n",
       "            original_name=Sequential\n",
       "            (0): Dropout(original_name=Dropout)\n",
       "            (1): Sequential(\n",
       "              original_name=Sequential\n",
       "              (0): Sequential(\n",
       "                original_name=Sequential\n",
       "                (0): Linear(original_name=Linear)\n",
       "                (1): BatchNorm1d(original_name=BatchNorm1d)\n",
       "                (2): Tanh(original_name=Tanh)\n",
       "              )\n",
       "              (1): Sequential(\n",
       "                original_name=Sequential\n",
       "                (0): Linear(original_name=Linear)\n",
       "                (1): BatchNorm1d(original_name=BatchNorm1d)\n",
       "                (2): Tanh(original_name=Tanh)\n",
       "              )\n",
       "            )\n",
       "            (2): Linear(original_name=Linear)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compiled_traced_partial_model = torch.compile(traced_partial_model)\n",
    "d(compiled_traced_partial_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.save(compiled_traced_partial_model, \"./ckpts/burger_1d_unord_v2/burgers_1d_unord_v2_emb32_extreme_time.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4746709585189821\n"
     ]
    }
   ],
   "source": [
    "_time = 0.0\n",
    "n_iters = 20_000\n",
    "\n",
    "for _ in range(n_iters):\n",
    "    start_time = time()\n",
    "    partial_model(*sample);\n",
    "    # traced_partial_model(*sample);\n",
    "    _time += time() - start_time\n",
    "\n",
    "print(_time / n_iters * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.38 ms ± 21.2 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "824 µs ± 12.4 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "928 µs ± 18.9 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit partial_model(*sample)\n",
    "%timeit traced_partial_model(*sample)\n",
    "%timeit compiled_traced_partial_model(*sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightning & ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dynamic shape axis should be no more than the shape dimension for N",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[171], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartial_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./ckpts/burgers_1d_v1.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoords\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msolution\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoords\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/onnx/utils.py:516\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;129m@_beartype\u001b[39m\u001b[38;5;241m.\u001b[39mbeartype\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexport\u001b[39m(\n\u001b[1;32m    191\u001b[0m     model: Union[torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptFunction],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m     autograd_inlining: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;124;03m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m     \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/onnx/utils.py:1613\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m   1610\u001b[0m     dynamic_axes \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1611\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[0;32m-> 1613\u001b[0m graph, params_dict, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_model_to_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_do_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[38;5;66;03m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[1;32m   1627\u001b[0m defer_weight_export \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1628\u001b[0m     export_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _exporter_states\u001b[38;5;241m.\u001b[39mExportTypes\u001b[38;5;241m.\u001b[39mPROTOBUF_FILE\n\u001b[1;32m   1629\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/onnx/utils.py:1139\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1136\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1139\u001b[0m     graph \u001b[38;5;241m=\u001b[39m \u001b[43m_optimize_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_disable_torch_constant_prop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_disable_torch_constant_prop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1150\u001b[0m     torch\u001b[38;5;241m.\u001b[39monnx\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch IR graph at exception: \u001b[39m\u001b[38;5;124m\"\u001b[39m, graph)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/onnx/utils.py:674\u001b[0m, in \u001b[0;36m_optimize_graph\u001b[0;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001b[0m\n\u001b[1;32m    672\u001b[0m     input_names \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m input_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m input_names\n\u001b[1;32m    673\u001b[0m     dynamic_axes \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m dynamic_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dynamic_axes\n\u001b[0;32m--> 674\u001b[0m     \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jit_pass_onnx_set_dynamic_input_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    675\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[1;32m    677\u001b[0m graph \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx(graph, operator_export_type)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dynamic shape axis should be no more than the shape dimension for N"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(\n",
    "    model=partial_model,\n",
    "    args=tuple(sample),\n",
    "    f=\"./ckpts/burgers_1d_v1.onnx\",\n",
    "    input_names=[\"coords\", \"time\"],\n",
    "    output_names=[\"solution\"],\n",
    "    # dynamic_axes={\n",
    "    #     \"coords\": {0: \"batch_size\", 1: \"N\"},\n",
    "    #     \"time\": {0: \"batch_size\", 1: \"N\"}\n",
    "    # }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ir_version: 8\n",
       "opset_import {\n",
       "  version: 17\n",
       "}\n",
       "producer_name: \"pytorch\"\n",
       "producer_version: \"2.2.2\"\n",
       "graph {\n",
       "  node {\n",
       "    input: \"model_batch\"\n",
       "    input: \"onnx::MatMul_53\"\n",
       "    output: \"/layers/layers.0/partial_model/branched_linear_block_xyz.0/branched_linear_block_xyz.0.0/MatMul_output_0\"\n",
       "    name: \"/layers/layers.0/partial_model/branched_linear_block_xyz.0/branched_linear_block_xyz.0.0/MatMul\"\n",
       "    op_type: \"MatMul\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"layers.0.partial_model.branched_linear_block_xyz.0.0.bias\"\n",
       "    input: \"/layers/layers.0/partial_model/branched_linear_block_xyz.0/branched_linear_block_xyz.0.0/MatMul_output_0\"\n",
       "    output: \"/layers/layers.0/partial_model/branched_linear_block_xyz.0/branched_linear_block_xyz.0.0/Add_output_0\"\n",
       "    name: \"/layers/layers.0/partial_model/branched_linear_block_xyz.0/branched_linear_block_xyz.0.0/Add\"\n",
       "    op_type: \"Add\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"/layers/layers.0/partial_model/branched_linear_block_xyz.0/branched_linear_block_xyz.0.0/Add_output_0\"\n",
       "    output: \"/layers/layers.0/partial_model/branched_linear_block_xyz.0/branched_linear_block_xyz.0.1/Tanh_output_0\"\n",
       "    name: \"/layers/layers.0/partial_model/branched_linear_block_xyz.0/branched_linear_block_xyz.0.1/Tanh\"\n",
       "    op_type: \"Tanh\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"/layers/layers.0/partial_model/branched_linear_block_xyz.0/branched_linear_block_xyz.0.1/Tanh_output_0\"\n",
       "    output: \"/layers/layers.0/partial_model/Concat_output_0\"\n",
       "    name: \"/layers/layers.0/partial_model/Concat\"\n",
       "    op_type: \"Concat\"\n",
       "    attribute {\n",
       "      name: \"axis\"\n",
       "      type: INT\n",
       "      i: 1\n",
       "    }\n",
       "  }\n",
       "  node {\n",
       "    input: \"onnx::MatMul_3\"\n",
       "    input: \"onnx::MatMul_54\"\n",
       "    output: \"/layers/layers.0/partial_model/linear_block_t/linear_block_t.0/MatMul_output_0\"\n",
       "    name: \"/layers/layers.0/partial_model/linear_block_t/linear_block_t.0/MatMul\"\n",
       "    op_type: \"MatMul\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"layers.0.partial_model.linear_block_t.0.bias\"\n",
       "    input: \"/layers/layers.0/partial_model/linear_block_t/linear_block_t.0/MatMul_output_0\"\n",
       "    output: \"/layers/layers.0/partial_model/linear_block_t/linear_block_t.0/Add_output_0\"\n",
       "    name: \"/layers/layers.0/partial_model/linear_block_t/linear_block_t.0/Add\"\n",
       "    op_type: \"Add\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"/layers/layers.0/partial_model/linear_block_t/linear_block_t.0/Add_output_0\"\n",
       "    output: \"/layers/layers.0/partial_model/linear_block_t/linear_block_t.1/Tanh_output_0\"\n",
       "    name: \"/layers/layers.0/partial_model/linear_block_t/linear_block_t.1/Tanh\"\n",
       "    op_type: \"Tanh\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"/layers/layers.0/partial_model/Concat_output_0\"\n",
       "    input: \"/layers/layers.0/partial_model/linear_block_t/linear_block_t.1/Tanh_output_0\"\n",
       "    output: \"/layers/layers.0/partial_model/Concat_1_output_0\"\n",
       "    name: \"/layers/layers.0/partial_model/Concat_1\"\n",
       "    op_type: \"Concat\"\n",
       "    attribute {\n",
       "      name: \"axis\"\n",
       "      type: INT\n",
       "      i: -1\n",
       "    }\n",
       "  }\n",
       "  node {\n",
       "    input: \"/layers/layers.0/partial_model/Concat_1_output_0\"\n",
       "    input: \"onnx::MatMul_55\"\n",
       "    output: \"/layers/layers.0/partial_model/out_linear_block/MatMul_output_0\"\n",
       "    name: \"/layers/layers.0/partial_model/out_linear_block/MatMul\"\n",
       "    op_type: \"MatMul\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"layers.0.partial_model.out_linear_block.bias\"\n",
       "    input: \"/layers/layers.0/partial_model/out_linear_block/MatMul_output_0\"\n",
       "    output: \"/layers/layers.0/partial_model/out_linear_block/Add_output_0\"\n",
       "    name: \"/layers/layers.0/partial_model/out_linear_block/Add\"\n",
       "    op_type: \"Add\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"/layers/layers.0/partial_model/out_linear_block/Add_output_0\"\n",
       "    input: \"onnx::MatMul_56\"\n",
       "    output: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.0/linear_block.0.0/MatMul_output_0\"\n",
       "    name: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.0/linear_block.0.0/MatMul\"\n",
       "    op_type: \"MatMul\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"layers.1.partial_model.linear_block.0.0.bias\"\n",
       "    input: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.0/linear_block.0.0/MatMul_output_0\"\n",
       "    output: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.0/linear_block.0.0/Add_output_0\"\n",
       "    name: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.0/linear_block.0.0/Add\"\n",
       "    op_type: \"Add\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.0/linear_block.0.0/Add_output_0\"\n",
       "    output: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.0/linear_block.0.2/Tanh_output_0\"\n",
       "    name: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.0/linear_block.0.2/Tanh\"\n",
       "    op_type: \"Tanh\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.0/linear_block.0.2/Tanh_output_0\"\n",
       "    input: \"onnx::MatMul_57\"\n",
       "    output: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.1/linear_block.1.0/MatMul_output_0\"\n",
       "    name: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.1/linear_block.1.0/MatMul\"\n",
       "    op_type: \"MatMul\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"layers.1.partial_model.linear_block.1.0.bias\"\n",
       "    input: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.1/linear_block.1.0/MatMul_output_0\"\n",
       "    output: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.1/linear_block.1.0/Add_output_0\"\n",
       "    name: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.1/linear_block.1.0/Add\"\n",
       "    op_type: \"Add\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.1/linear_block.1.0/Add_output_0\"\n",
       "    output: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.1/linear_block.1.2/Tanh_output_0\"\n",
       "    name: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.1/linear_block.1.2/Tanh\"\n",
       "    op_type: \"Tanh\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.1/linear_block.1.2/Tanh_output_0\"\n",
       "    input: \"onnx::MatMul_58\"\n",
       "    output: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.2/linear_block.2.0/MatMul_output_0\"\n",
       "    name: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.2/linear_block.2.0/MatMul\"\n",
       "    op_type: \"MatMul\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"layers.1.partial_model.linear_block.2.0.bias\"\n",
       "    input: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.2/linear_block.2.0/MatMul_output_0\"\n",
       "    output: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.2/linear_block.2.0/Add_output_0\"\n",
       "    name: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.2/linear_block.2.0/Add\"\n",
       "    op_type: \"Add\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.2/linear_block.2.0/Add_output_0\"\n",
       "    output: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.2/linear_block.2.2/Tanh_output_0\"\n",
       "    name: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.2/linear_block.2.2/Tanh\"\n",
       "    op_type: \"Tanh\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.2/linear_block.2.2/Tanh_output_0\"\n",
       "    input: \"onnx::MatMul_59\"\n",
       "    output: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.3/linear_block.3.0/MatMul_output_0\"\n",
       "    name: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.3/linear_block.3.0/MatMul\"\n",
       "    op_type: \"MatMul\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"layers.1.partial_model.linear_block.3.0.bias\"\n",
       "    input: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.3/linear_block.3.0/MatMul_output_0\"\n",
       "    output: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.3/linear_block.3.0/Add_output_0\"\n",
       "    name: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.3/linear_block.3.0/Add\"\n",
       "    op_type: \"Add\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.3/linear_block.3.0/Add_output_0\"\n",
       "    output: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.3/linear_block.3.2/Tanh_output_0\"\n",
       "    name: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.3/linear_block.3.2/Tanh\"\n",
       "    op_type: \"Tanh\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.3/linear_block.3.2/Tanh_output_0\"\n",
       "    input: \"onnx::MatMul_60\"\n",
       "    output: \"/layers/layers.1/partial_model/cls_layers/out_block/MatMul_output_0\"\n",
       "    name: \"/layers/layers.1/partial_model/cls_layers/out_block/MatMul\"\n",
       "    op_type: \"MatMul\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"layers.1.partial_model.out_block.bias\"\n",
       "    input: \"/layers/layers.1/partial_model/cls_layers/out_block/MatMul_output_0\"\n",
       "    output: \"/layers/layers.1/partial_model/cls_layers/out_block/Add_output_0\"\n",
       "    name: \"/layers/layers.1/partial_model/cls_layers/out_block/Add\"\n",
       "    op_type: \"Add\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"/layers/layers.1/partial_model/cls_layers/out_block/Add_output_0\"\n",
       "    output: \"52\"\n",
       "    name: \"/layers/layers.1/partial_model/cls_layers/cls_layers.3/Tanh\"\n",
       "    op_type: \"Tanh\"\n",
       "  }\n",
       "  name: \"main_graph\"\n",
       "  initializer {\n",
       "    dims: 16\n",
       "    data_type: 1\n",
       "    name: \"layers.0.partial_model.branched_linear_block_xyz.0.0.bias\"\n",
       "    raw_data: \"\\317\\340\\020?\\273\\243=\\275\\237\\\\\\n?\\300\\367\\010?\\250\\2240\\277\\270w6?\\316\\321\\222\\276\\247jt?\\305\\301<>\\327\\266Y?{\\234\\024\\277\\n\\373N?f7e\\277\\345\\260|\\277\\346\\2103?\\272\\002:>\"\n",
       "  }\n",
       "  initializer {\n",
       "    dims: 16\n",
       "    data_type: 1\n",
       "    name: \"layers.0.partial_model.linear_block_t.0.bias\"\n",
       "    raw_data: \"TZ\\021?g\\301\\300<\\352\\237\\001\\277\\305l\\035?\\254\\202\\225\\276k\\306\\007>\\233A\\225\\273S\\005 \\276\\020\\r\\233\\276\\345\\237\\037>k1\\237\\276\\002\\252\\n\\277\\014i\\270\\276\\317O\\024\\277\\351]%?V\\301\\035\\277\"\n",
       "  }\n",
       "  initializer {\n",
       "    dims: 16\n",
       "    data_type: 1\n",
       "    name: \"layers.0.partial_model.out_linear_block.bias\"\n",
       "    raw_data: \"2\\221\\202>\\244\\314\\t=\\r\\207\\231=\\372\\010,\\274$\\207\\350\\273\\272:b\\276\\332\\204\\365\\275\\025\\317$\\275\\375ZA=\\247Oa>o1;>\\316\\224\\211\\276\\001~\\230\\274\\000\\314c>c\\317J\\274\\274-\\372\\274\"\n",
       "  }\n",
       "  initializer {\n",
       "    dims: 16\n",
       "    data_type: 1\n",
       "    name: \"layers.1.partial_model.linear_block.0.0.bias\"\n",
       "    raw_data: \"\\'e\\276=w\\036\\014\\276\\333\\343c\\276{\\234T\\276\\235\\037\\340\\275\\335I\\276\\275>\\032\\326\\275\\331S\\354\\275\\253I\\033>:\\323\\337\\275\\032\\244\\006>6\\354;>\\340~\\r>\\342\\351\\260=\\350\\336\\366<N\\376g\\275\"\n",
       "  }\n",
       "  initializer {\n",
       "    dims: 16\n",
       "    data_type: 1\n",
       "    name: \"layers.1.partial_model.linear_block.1.0.bias\"\n",
       "    raw_data: \"\\202\\271\\007=\\2575\\201\\276\\322,\\264\\275<\\344+>xEZ>\\270\\213\\273\\275\\000{\\001>3j\\022>\\tu\\256=\\255\\211o\\275/$\\254=\\235G\\035\\276\\'\\230w=\\255\\322I\\276q\\267\\027\\276\\236G\\221\\276\"\n",
       "  }\n",
       "  initializer {\n",
       "    dims: 16\n",
       "    data_type: 1\n",
       "    name: \"layers.1.partial_model.linear_block.2.0.bias\"\n",
       "    raw_data: \"\\320\\323\\271\\275\\315C\\\\\\276\\311\\361\\262\\275\\230\\227L\\276\\203Ei>\\214C\\272=\\'\\343\\257\\275\\273\\322\\266\\275\\225\\374>\\276\\240M\\271=\\260\\336\\010>\\241w\\232<\\013\\013\\243=\\355\\346J\\276-F\\001\\276\\246jD\\275\"\n",
       "  }\n",
       "  initializer {\n",
       "    dims: 16\n",
       "    data_type: 1\n",
       "    name: \"layers.1.partial_model.linear_block.3.0.bias\"\n",
       "    raw_data: \"r+\\033\\276\\337\\343@\\276$\\210\\n\\276 Z\\017=\\253\\024\\371=\\341\\031\\002\\276\\342\\2112>#\\004\\227\\275Pm\\312\\275\\t\\037\\177<5\\356\\t>\\270\\302\\n\\276\\375\\251\\263=\\311\\3729>`\\336\\010>\\2541\\235\\274\"\n",
       "  }\n",
       "  initializer {\n",
       "    dims: 1\n",
       "    data_type: 1\n",
       "    name: \"layers.1.partial_model.out_block.bias\"\n",
       "    raw_data: \"\\0142v\\276\"\n",
       "  }\n",
       "  initializer {\n",
       "    dims: 1\n",
       "    dims: 16\n",
       "    data_type: 1\n",
       "    name: \"onnx::MatMul_53\"\n",
       "    raw_data: \"|\\262X\\277\\237\\3237?IC\\031\\276\\304\\'a?\\222\\366A\\275G`X\\277s+\\257?&\\315\\216<\\2268\\377>\\347\\267\\367\\275\\225\\376\\202?\\275\\007\\201\\277lox?dw\\233\\277\\215\\224\\023?0\\262\\260?\"\n",
       "  }\n",
       "  initializer {\n",
       "    dims: 1\n",
       "    dims: 16\n",
       "    data_type: 1\n",
       "    name: \"onnx::MatMul_54\"\n",
       "    raw_data: \"\\255p\\336?Q\\314\\231?\\210\\227\\245?/\\232^\\2779\\020\\377\\276P+u\\277\\267\\264G?Bq\\210\\277\\375\\205\\031??L\\031>Tr<?\\306\\025\\201\\275\\321eT>\\270i\\337\\275\\027r\\227\\276N\\233i\\277\"\n",
       "  }\n",
       "  initializer {\n",
       "    dims: 32\n",
       "    dims: 16\n",
       "    data_type: 1\n",
       "    name: \"onnx::MatMul_55\"\n",
       "    raw_data: \"\\275|)\\276<\\n\\013>\\326\\231\\211=\\227\\223\\273\\275\\3156\\003<Dh2>\\273\\301\\340=\\210~(>\\020\\343\\235<\\034-\\254\\274\\210\\230\\305=\\'\\253:>\\277\\362=>\\362g\\215\\276K\\337\\273\\275h\\310\\035\\276\\364\\003\\314=\\243\\274\\322=\\027;Y\\274\\321\\355j<ieQ\\276\\275\\t\\270\\274B\\'\\023=\\203\\322\\014>^0\\025\\276G\\231\\'\\276\\023\\362W>\\226J\\354=\\375\\026,>\\325\\307:=\\331~\\335\\2742T\\303=\\361K&>(*\\021\\274\\375\\337\\355=a\\353\\241\\274tC\\345=\\271\\255\\316\\275P\\356}\\274\\275\\360/\\274f\\226\\021\\276I\\361\\233=\\224\\322\\332\\274\\330{\\021\\276\\331\\342_\\2759\\362\\020>1r\\203=\\314\\033\\224\\2750\\270\\261\\276\\207\\211\\035\\275|\\036G\\276[c\\216>L\\344\\013=\\023x\\345>\\254\\030Z>\\025\\321@>e\\267/>\\346\\345N\\276T\\r?>fg\\316>\\006\\370\\304>&\\337\\017\\274\\033d\\000=\\\\oP>\\035\\r\\024\\2769\\214\\202=\\327\\207M\\276*\\212q\\275M\\377\\305<Z\\303\\236>8\\\"w=\\037\\263\\275=\\266\\202\\342\\275\\237\\344_\\276\\243\\263\\276<\\254\\001\\225<\\250m\\267\\274\\222g\\373\\275\\244\\032\\323\\274E\\303\\261=|\\321b\\276\\036\\013\\215\\275\\032{\\256=\\223\\2402\\275\\275\\271\\356=\\317\\201\\205>\\311\\305{\\275\\013\\347{>d\\004\\340\\274\\377z\\224\\276\\025_\\001\\276\\311\\214\\320<\\013?1<\\tH\\377\\276]\\326X\\276o\\326v=\\370\\304\\304>\\336\\205\\221>\\005\\334\\257\\275O\\244\\213\\276N\\013\\205=\\262\\224-\\276\\350\\007\\217\\276\\373\\0208>noh\\276\\245\\303\\304\\274D\\275\\206<\\ty\\234\\275\\001\\366\\326\\274\\354k\\242=9\\020\\203\\276N\\237`>\\243\\310=\\275\\310\\346\\241\\275e\\260]>\\225\\205f\\276\\244\\264\\020>\\033I\\275\\275\\212\\214\\212\\274\\331/\\375<S\\203\\321\\275\\223_\\243=c\\215\\\"\\275{\\324\\263\\275\\361\\260d\\275l\\366\\212>\\305\\n\\024=b\\214w\\276\\306n\\206\\276\\343\\276\\253\\275\\355\\341\\207\\274\\365\\022\\222>\\200Eb\\276\\276\\3425>O@\\035>\\335M\\020\\275T\\310B>1U\\314\\275\\376\\224_>\\2278<=\\006x\\200>\\001F\\351\\274q}\\336=0\\267\\245\\275\\340\\310\\340<\\364\\356\\'\\276 \\227\\373=v\\177\\254\\275\\215\\226\\022>\\001D~\\275\\270\\222P\\276\\355\\201(>|Q\\027>\\255)+>V=&=\\375Tu\\276\\3402\\034\\276\\034\\316G>\\363\\303\\016\\2761\\027E\\276\\270\\0072=5\\262\\025=\\200x\\004\\276\\243\\332\\250\\271\\031\\344\\024\\276\\302\\336\\014\\276{\\017\\311=\\305\\302+\\274\\302I\\010\\276\\304\\337*>\\235\\2670>\\220F\\213\\276\\356/\\\\\\276Na\\354>\\030\\340\\311\\275\\266\\272\\367\\274]\\362\\006\\276\\362K\\241\\275\\274r\\211\\275Rf>=\\350\\225<=\\257\\323\\016>\\3648\\367\\275\\026WV>\\233s\\210<\\257mj\\276\\010\\321F\\276\\374\\364\\270>8\\361\\265=h\\212\\377\\276\\327[\\023\\276j\\300\\037\\275\\337\\246Q>\\236\\032\\274\\275\\241\\nu>\\247\\326\\n>\\347\\366\\024\\276\\354\\005~\\276\\325\\375)>\\t.\\035\\275\\203\\212%\\276\\\"\\350)>E\\030\\321=P6*\\276\\336\\344:\\275\\214\\001\\265>^\\346\\206=h\\256\\345\\274\\345\\233\\255>\\264\\361,=\\277\\335\\236\\275P=\\311\\275\\262\\360\\204>\\030\\310\\270\\276\\022L\\233\\276nm\\242\\275x\\350\\330\\276\\000\\022\\274>\\317A<\\276\\n\\353\\361\\276\\247U\\321\\276B\\035\\300>\\373{\\177\\274\\032\\270\\364<\\302\\0209=\\250\\322\\354\\275\\034\\263\\001\\276\\337?5=}\\217\\362\\274\\030X\\000\\276\\201~k>O7+>L\\033\\177>%\\207\\321=\\311\\203f>\\351\\036X>\\235\\200\\213>\\331\\357\\341\\274TG\\343=\\002>\\207=\\254\\353]>O\\314\\234>\\364\\034m\\275#/\\376\\274\\212\\\"\\000<\\337Q\\004>^\\205e<eB\\205>d\\005\\271<\\031_\\262\\276\\232\\271\\261<)\\261A\\275\\022\\033->\\301\\271\\275\\276\\211\\024\\225\\276\\331\\017|>F\\004#>>\\027\\023=F\\354a>\\311\\227\\n\\276\\2730\\315>*\\036~\\276\\346\\313\\\\\\276\\251:\\215>\\334\\036\\242\\274\\276\\314\\375=t\\'\\204>\\311\\356\\235\\276Lx\\242\\275\\027\\376\\246>\\313\\014\\327=\\\"\\316\\347\\275\\257\\321n>T\\001I\\276\\345\\245\\227=N&\\372;\\201\\312\\267=\\277\\004\\256\\275\\326o\\272\\275G~\\303<\\273\\214\\343=\\201ju>U[\\033>\\264\\262-\\275\\340\\226\\n=\\204\\022\\336=\\343\\272\\223\\275_\\345\\214\\276@%\\223=\\261\\2246\\276*\\300O>{;\\367\\275\\377\\345\\357\\275aJ\\346<jR\\021=`\\374\\217<1\\247\\265\\275\\210C\\264<B\\235\\n>`\\267$>g\\314*>\\256+\\233\\2746y?>q\\374\\010\\276r\\330\\242=w\\3126>3*\\322<\\341\\316!>\\223]f\\275&~P\\275\\236\\\"1\\273\\0345\\246\\275\\316=\\223\\275\\326\\356\\005\\2764r\\024>C\\016\\324\\274KG:>/c?>\\\"\\320\\331=\\275\\246<>\\377\\212~\\276\\035\\353<>\\247!\\003<\\344[;>\\027\\276\\224\\276y_H=\\334\\372\\307\\273STO\\276\\016\\264\\235=\\341Y{\\276$\\337`=\\3756?>\\330\\r\\233=^\\367g\\276!\\3002>\\357\\t~>\\231\\353G\\276\\t\\3717>k\\224l\\276JK/=\\017\\211r\\276\\365\\200\\r>\\223\\324k\\275w\\016*\\276\\034\\300\\322=F\\242\\033\\276\\242\\322\\333=gA[\\275\\tn\\265\\274\\007\\2054\\275D\\367\\035\\276!\\365\\220>\\343\\235B\\271\\306\\353\\177\\275\\177\\360W\\275=L\\213\\275\\213\\215\\223=H\\247\\374\\275\\345}?\\275\\247\\326\\352=i\\034\\244\\275c\\233p>J7*>\\320/(\\276\\n\\200\\301\\275\\232\\\"\\031>\\243W\\003\\276[zv\\276\\270!\\202\\276c\\037\\205>\\304-1\\276\\342\\022L\\275!\\031\\237\\276~\\375m=\\0072\\315;\\234c\\212\\276\\031\\035\\345\\275x/\\273\\275.\\315\\344\\275\\201\\226\\016>ei\\273<\\206\\016G=\\213h\\242\\275q\\321\\257>\\002\\'\\206=\\024)\\240=x5F\\274lo+=\\340\\230\\271=\\236_\\213=\\330B\\330\\273\\003\\235\\013>\\3774\\346\\274\\336|\\203=\\257B\\242=X\\275\\301\\273\\020G-\\276>{\\340\\2755\\2730\\275\\014U\\213\\275Y\\324l>\\265\\n*\\2752Y|>\\\"}Y\\276i\\263a\\274\\354\\377\\217\\276q\\177\\016\\2768>/>\\205\\332\\032\\276\\002\\200->\\035lc=;\\306\\207\\275f\\337T\\276\\365_\\256>\\360`\\370=\\334\\224K\\276u\\035\\300\\275\\255DI\\276\\177\\315\\225\\275 \\303\\030\\276\\n\\346\\242=\\351LQ<do%\\276k\\275\\224\\275\\316\\3441\\276\\037\\326\\331=\\\"N\\340\\2751\\213\\233\\275z>\\321\\273\\350\\256+\\274\\220\\335\\007>\\030\\267>\\276\\311Y\\215<\\237\\252P\\275#\\321\\323=.Z\\000;\\213\\000V=J\\350 >\\254\\264>>\\333W\\324\\274I\\\"`<\\250\\265\\212\\275\\020\\270G\\275\\260\\316n=!\\216\\224\\275\\300=\\326\\273\\322\\301Y\\274\\2478Q>%\\030\\315=\\202\\006\\247;\\346O^>\\227UY\\276\\341\\002\\263\\2744u\\201\\276\\372\\\\`\\275\\324_\\350=\\343\\301[\\276r:@=\\363\\'0>\\234\\220#\\276\\276\\321E\\276\\245Dn=\\303\\006E>\\016V:\\276\\032\\036\\3429]\\036N\\275\\221\\341U\\276n\\257X\\275\\242\\266J\\275\\351\\212\\307=\\313\\204T\\275R\\034\\274=\\371\\377=>\\333\\002\\004\\275\\034\\002!=\\026{\\210>\\3227\\276\\275,\\343\\023\\276\\343\\302\\021>\\250\\020@=\\026L\\360\\275\\302\\323\\311\\275\\\"\\026N\\275A\\030\\264\\275\\\"\\010F\\276\\270R\\026<\\355\\212\\350=\\236\\325\\331=\\222\\317\\247\\275\\340\\311\\252\\275#\\017\\250=k\\234g>\\274\\322\\023>$\\'\\232\\274\\372\\325>\\276A\\240\\025=\\244\\334\\243\\276\\\"\\020\\314\\274\\331\\364P;A\\243\\r>B\\004a\\276\\273\\376\\241>1\\373z>\\224R\\362\\275H\\226\\001>\\234\\335\\346\\275\\270\\226j\\274C\\351\\255=\\270\\016\\230=\\322@\\210\\276I\\330\\027=L\\3001>\"\n",
       "  }\n",
       "  initializer {\n",
       "    dims: 16\n",
       "    dims: 16\n",
       "    data_type: 1\n",
       "    name: \"onnx::MatMul_56\"\n",
       "    raw_data: \"\\242^\\227\\276A\\203>\\276O}z\\275VR\\305\\275\\247\\335W>\\021\\0028\\276\\271,\\016?\\227$\\006>8%k\\2764y\\\">\\002\\277\\276\\276\\351K\\013\\276\\260\\350>>\\2502\\316\\275\\345\\236\\367\\275b\\023\\037=\\307\\2511>\\344ku>^\\022\\025\\276~\\337\\261=\\014W\\n>\\3549\\311=\\0255\\245>&\\342@>\\017\\230\\314\\275=\\356\\037\\276vd\\276<w\\253\\020\\276\\214_\\353\\276;Pb\\276\\244:\\205\\275w\\225$>\\342\\216\\204=\\302\\023\\244\\276\\306\\301u<7\\241k\\276\\263\\372?>k\\234E\\276\\'!&>5\\274&\\274\\'m\\331\\275\\245?+<\\226\\377\\236\\276\\035L5>\\302\\242\\332>3\\367\\n>\\004\\232#\\276\\017\\357P\\276i\\253\\037\\275\\322T\\240=C\\\\\\210<\\317\\275O\\276l\\231\\336\\275\\230!\\331=&\\242\\000\\276\\226-\\004=9E\\327=\\357j\\361\\2754G\\200>\\306\\030\\253>\\224a\\004\\2778\\274\\004\\276\\253\\251c\\275\\365?\\316\\275\\301\\351 \\275\\333\\036\\253\\276\\222\\370\\213\\275_\\310+\\276\\212xn>\\3054\\017\\276\\232\\357A=\\353\\361\\265=\\002\\007N>\\030R\\226>\\371\\271\\246\\273#\\005\\016\\275\\020s\\336>LmG\\276\\325^\\006\\275\\013\\023\\265\\275\\226\\234\\347>\\363e\\333>\\244\\004*\\274fv\\003\\276\\371\\n\\355\\276\\326\\375\\241\\275\\362\\274\\024\\277\\212\\0344<\\264\\315*=\\266\\212\\230:\\332\\200\\336>\\234\\t\\242=\\250\\337W\\275g\\260\\203\\276\\022\\221\\224>V\\\\\\227\\275#\\265\\r>\\377\\212\\206>\\2362W>\\347\\244\\004\\276\\241\\260A\\276\\367L\\250=\\327\\201\\357\\2751d\\001\\276\\300\\233w\\275\\\\N\\322\\276\\010\\202\\216>\\343\\201|>\\3573\\030\\277\\274\\226\\236\\274\\346Ui<\\\\\\344;\\276\\251V\\025>\\365|a\\276\\036\\352\\376=\\004\\243\\215>\\255Y\\230>\\245\\300u\\276\\247\\257W\\276S\\246\\260=|\\351\\234>\\232\\214B>h\\256\\013\\276\\266\\357\\025\\276\\344gt>\\322I\\252\\276\\225L\\222>lV\\016\\276\\243~\\333>Q\\255\\346\\274\\242\\1771=\\016\\2615>\\303i4\\276,d\\332<\\037\\237\\324\\276\\277+:>\\350\\346T\\275B\\273\\357=\\326\\362\\017?M`>>E\\335\\002=\\206\\363T>\\265\\005\\230>\\024j=\\276\\364\\213\\355\\275\\0220\\354\\276\\314*8=?\\237l\\275\\247j\\037>R\\177G\\276!\\005\\205>\\233\\215\\236\\276\\215\\2540\\276w\\205\\021>\\223\\335\\331\\276\\002b\\213\\276\\272\\326\\327=\\2008\\266>u|\\257\\276\\202\\350\\014\\276\\364%5>@]\\367=\\310\\310,>=n\\312=gP\\260>\\264z\\267=6B\\306=\\301@\\205>w8\\232;\\004!y=\\221\\266\\022\\276\\250\\037k\\275(\\233=\\276\\341x9>\\017\\211\\014>\\027;\\302\\276\\tz\\201>\\204\\255\\233>\\346\\250\\237>c\\236\\177>\\312!\\365\\276`\\\\\\206<Ls\\017\\277\\375Z\\026>\\333\\001\\024>\\352\\021\\377\\274\\262(\\014?\\262U\\250>\\007\\202\\330\\274\\250\\276\\274\\275\\025}\\340=\\037\\360x\\275|\\263%>)\\276\\343=\\366\\362\\330=`\\272\\266\\275y\\365\\276=\\260\\3753\\274\\r\\231\\277\\276\\010\\020Y>\\001\\313\\322=\\315\\354Y\\276\\245\\220\\317>\\031\\005\\022>\\177\\t\\376\\274t\\354\\207\\276r\\355\\037\\275\\353\\223T\\276\\007\\216\\310\\276|P\\035\\276\\256\\243\\252\\276\\320\\334\\226\\276\\225\\230\\005?%\\027I=r\\014\\034?c\\360\\007\\275F\\376\\037\\276f\\256Z=_\\347\\005\\277\\322\\210#>\\025(D\\276\\340\\246Y>\\317\\271\\241\\276Rl\\235\\275\\304\\237\\010>\\253\\322\\323\\275\\273\\376\\010\\276;)\\227\\276\\250\\231\\221\\276\\023\\\\\\335<RF|=u\\016\\013\\275\\267J\\351=\\037(M\\2756\\266\\036\\276G<->\\217/\\'\\275\\243\\365\\201>\\274\\334\\217\\276\\220\\357\\026\\276\\007+G<\\211\\260\\327>\\331\\227T>AIy>\\261`\\223\\275\\2112\\361=\\'\\202\\245=Td\\022\\274\\234\\001K\\276\\006\\364\\377\\275\\301\\004S\\274\\342X\\350\\274]\\202\\030\\277Yd\\353<\\232\\320\\335=\\242zB>\"\n",
       "  }\n",
       "  initializer {\n",
       "    dims: 16\n",
       "    dims: 16\n",
       "    data_type: 1\n",
       "    name: \"onnx::MatMul_57\"\n",
       "    raw_data: \"HNi>\\276\\357\\213>\\365>\\025>\\327`\\212>\\253\\216\\201=\\372\\311\\252>yU\\363\\275\\240\\341r\\276E\\244\\254\\271d7f>c\\027\\311\\275\\343\\027~=\\347\\343z\\276\\264(\\006>\\3024\\243>JSX>>s\\233>\\340xZ>J\\307\\203\\276V\\260t<\\200.\\230\\276_I\\032>x[\\256\\276\\267X\\313\\275r;\\233>\\254Z-\\275\\253\\014u\\276\\004i\\264\\275To\\273\\273BH\\210>\\221]\\224\\273\\000\\271\\000\\276\\220\\303,\\276p-\\213=\\265\\2602>R\\317U\\275\\216\\301 >\\320\\0329>z\\213\\020\\276\\223p\\021>\\353\\305\\032\\276p\\235\\272\\275\\206\\203\\217=\\246\\2458>\\004j\\272=\\241\\312\\003>bu\\235>\\017\\321V>\\310\\304P>\\303\\325\\236>lp\\350\\275\\211\\314\\323=\\222\\030!\\274$_\\322=\\204eL\\276C\\344&>\\213m\\231>0P\\206\\275\\351\\016L=\\367\\n\\204\\275qkM=S\\326\\307\\275\\231\\243Z>\\221I\\216\\275\\326t\\336\\275/\\251\\212>\\211\\242P\\276\\013\\320\\252;\\215\\325\\322\\275\\300.\\342\\275\\222\\036N\\276\\216\\340\\240>\\336\\212\\177>\\346Z+\\275&\\265n\\275\\030\\322\\017\\276\\353\\'\\216>7\\213\\202>\\001 \\235>\\004\\025\\006\\2779#\\262=xY\\030\\276l\\n\\t>\\035r$\\276\\211C~\\276\\216}\\354<2\\206\\313=?\\\"]<\\270\\035-\\276\\220\\016\\\\>\\256!\\367\\275\\260\\241\\027>\\340\\230\\373\\275\\231[\\203>\\022\\353\\262\\275E5\\300\\275b\\017\\245\\275\\354\\335\\257\\276T\\234\\313\\276\\010I\\256\\276Fd\\267\\274\\277!\\226\\276z\\'@>\\264Q\\374=\\3369\\267\\275&^\\254\\276 \\034\\354>\\205v\\276\\275\\250\\n\\247\\274\\300B\\200\\276\\\"\\356M\\276\\261\\313\\026\\277\\367Dw\\276\\326\\004\\213>\\234\\221\\023>t\\373\\310=9\\256\\237<@\\373\\t>\\32667>#\\006\\243>_\\013R\\276\\374\\312\\220\\273\\204\\311\\314\\275n\\364\\212\\275j\\\\F\\276\\217\\247\\225=z8\\224>\\023F\\270\\275\\317\\344`>z\\312\\203>H\\275}>ogC\\276rXL=Q\\353\\222>\\332\\3070\\276\\215\\254Z\\276\\242A\\372\\2757\\330\\210\\275L\\274\\375\\275\\247\\303a>\\275\\024\\016><\\362\\363=\\200\\004\\231>\\203P;>\\013\\350\\024>\\336\\333\\034=A\\224\\207\\2764:\\217\\276\\305&B\\276\\240M\\005=\\222B\\310=\\366n\\304=\\206zL\\276\\212ni\\276\\234\\354\\237=\\346\\204l\\276v\\tk>\\371\\356\\004\\276\\2563&\\276\\364\\203\\300\\273\\023\\263\\033>\\317\\363P>\\261\\344C>\\001|Z<\\007\\230\\377=\\345\\302\\354>\\360\\325\\032>\\212\\362R>\\300\\267\\016\\275\\370\\240\\362<\\316\\332\\344\\276\\214o\\313;\\361zH\\276\\235/\\217\\275\\014\\\"j>\\'\\340\\007?}m\\320\\275\\347\\335C=\\357K4>\\037\\242\\220>cQ\\364=\\211\\205\\221>\\214\\217\\226\\275&\\221\\201\\275`l~\\276\\013=C>li\\322\\275\\317;s>k~\\254\\276\\022\\341\\022\\276\\204%\\255\\275\\213K\\265>\\352\\344f\\2768\\200\\037\\276\\020H\\'>\\300j\\245\\2758bn\\276\\016l?\\273\\341\\245U>O\\021?\\276\\224\\323\\202>\\217\\242\\240={+^=\\\"4\\227\\276\\361t\\265>\\207@\\233\\275,\\263,>\\340-N>x\\037\\206\\276;>\\250\\276\\252(\\224\\273\\360K\\226>\\257]\\331<\\330\\324\\364\\275\\312\\0008>\\032Q\\262\\276\\350Q/\\2766\\000b>\\340\\216Z=\\344\\274O>\\337\\372 \\276\\2077.\\276\\271D\\255\\276O\\\"=\\276\\3062\\205>`\\337C>\\003\\335[\\276\\374\\311\\377=\\331\\006h<d\\304\\301>\\2410\\336=LL\\025=Z\\343\\234\\275\\261!k>\\033G\\215\\276\\332O\\177=\\306\\307l=l\\321\\245>\\003\\334\\335>\\366\\360{>-\\273\\334<\\014\\022\\264=\\367f!\\276j\\325\\320\\275Q\\005\\231\\276\\r{\\233\\2769\\215t\\276\\201G\\200\\275x\\205\\234>(;\\030\\276\\020Z\\204=\\254\\232\\\\\\276\\345N\\201>\\034\\226\\203>\\213\\302\\230\\275\\201\\203\\363=\"\n",
       "  }\n",
       "  initializer {\n",
       "    dims: 16\n",
       "    dims: 16\n",
       "    data_type: 1\n",
       "    name: \"onnx::MatMul_58\"\n",
       "    raw_data: \"X*\\034\\276<\\251\\357\\273x\\210\\213<Tb\\252>\\214\\350\\211=.6\\231>\\037\\350\\013>G\\222\\334>\\025\\026\\322=0+\\201\\276\\332\\225\\370=\\372\\036\\026\\276\\3751\\336=\\377\\3261=\\234\\361\\213>DV\\247=\\346\\217\\226>\\202\\307\\023\\275\\317\\3622\\276\\\";m\\275\\233\\230\\244>\\247\\3710>\\260\\354\\311>\\227\\007\\234>g\\031,\\276Asp\\276N\\2117\\276D1\\211=\\374f\\005>8\\351\\265>\\355\\335\\341=[\\r\\201>\\031l\\254<\\tu\\330\\275\\221F\\301>\\2727=\\276\\231\\254\\313\\274\\204\\006\\216\\275\\252K\\030\\276\\221O\\334\\275Z[\\277>Pu\\332\\275p\\363\\244>\\376\\331\\242\\276\\370k\\234>\\347\\r\\037<\\232\\241\\246\\276\\255\\211\\244\\276\\325l\\020>\\342o\\034<b\\310\\256>PY\\036\\275\\232\\'6\\2760\\241o<\\344\\315c>eb\\225=\\357\\033\\204>\\336\\237\\013\\276\\203Pb:\\243\\351l\\276\\033u\\234>\\211h:\\276\\373DH\\276\\306\\224\\270=\\371T\\321\\275\\267\\023\\004\\276<I\\260>\\201\\212!\\276\\211\\306j\\276\\242\\312r\\276:\\'\\214\\276\\227k\\322\\275\\333\\206\\031>b\\001$\\275;%\\326\\274C\\300\\236\\276O\\344\\205>\\366\\265,>\\220\\342\\022\\276R\\344\\241\\275J\\215 >\\035\\343\\264=\\333\\362\\333\\274K\\367\\237\\275\\331\\351\\006>\\271\\331~=)w\\337>\\237\\t\\271>?\\021\\'>\\347\\343\\251\\276\\312$E>\\2723;\\276\\017\\251\\310\\273#7&\\273\\326\\2357>#\\336\\323\\275\\021\\220\\333\\275\\262\\260S\\275\\364{~>\\036\\216\\371=\\2707\\037\\276\\312\\237P\\276\\365sz\\276\\376\\302\\320\\276\\017\\\"l=:\\001J>f`\\002\\275\\356\\260\\216\\2757\\250\\030>-\\351%>L+\\322=d-\\264<\\031\\033&>\\021\\n\\226\\275@\\007X\\274\\220\\001L>\\222E\\337\\274\\034y\\300=\\347\\214\\360\\274\\354\\305i>\\250\\021\\333\\275S\\206\\254\\275\\246\\026[\\276~\\241\\314\\275\\272I\\307\\275\\223\\212K>\\376\\341j>\\352\\030D>7\\317\\307=[\\203\\311<<\\323\\230\\276\\251\\033\\206>\\n\\266C>\\363\\226\\243>\\376\\274\\002\\274\\302\\002\\033>r\\177\\316\\276;\\211A\\276\\306\\223\\013\\276\\322{\\321>\\255\\3302\\276\\023m\\376=\\026\\t\\236;B`\\r>g\\253\\257\\275T7\\326<z\\017\\245>\\233\\026S>\\256Hb\\276\\320\\277t\\276\\354TT>\\230Z\\211>\\344<g>\\343\\006r\\276\\277\\373V>X\\007\\006=?\\342P>\\301\\326E>o/$\\276\\237\\261\\035\\276\\033_\\021=\\242\\355\\206=@\\233\\003\\276\\301mk\\276\\030\\3627\\276\\236L\\033=\\335K\\325\\276P4\\214\\276\\020\\206\\336\\275\\341N\\354=\\315{Z>\\342-\\212>k\\330\\225=\\221\\001\\221\\276\\306Rd>\\263\\261.>s\\032\\203\\276\\0248\\257\\273\\303\\212P>\\261\\232)\\275\\347N\\021=L\\235\\303\\274\\363\\235v>\\337\\317\\204;\\204\\200\\266\\275!\\316\\006\\275\\376\\010\\236>\\037(\\257\\276\\231q\\325=\\350\\277\\275\\275\\270wb\\276V\\036\\232\\276\\026\\221\\221\\275V\\022\\224=\\326g\\272\\275\\\\\\246v>\\206\\255\\026=~z\\014>\\214\\316\\213\\276t\\344\\230\\276\\206\\002\\025\\276-\\205\\311\\274\\366\\324\\244\\275\\3107\\227\\274\\302\\212V\\276w\\2148=\\370r\\243>\\370\\353(>\\241\\351*\\276<\\202\\375\\275\\337\\330\\264=\\021u\\207\\275O&6>\\312\\251\\226>\\210\\366\\336>\\342\\207\\272>\\227\\331\\223\\276(]n\\275o\\245o\\276\\377B8>\\307\\251\\261\\2757S\\202=Af\\330=y\\357\\343\\275\\352_\\014>\\333\\266\\312<?\\303{\\275iY\\264>\\2757\\250>\\203N\\320=\\205\\333\\325>\\004\\360\\347>)\\330\\305=\\246\\333m\\2768G\\003\\276C^\\225>\\013\\026\\026> r\\321>M\\365\\226\\274u\\030\\221>\\3577\\261\\276\\320\\305\\031\\276\\334\\305\\320>\\240E2\\276\\030y9<\\365)\\265=H\\230\\262\\2753\\357\\333=*\\216q>\\204\\273\\031>\\344\\363\\342<\\337\\313\\304\\276\\241B:\\274\\351\\nX\\275kt!<\\306\\254\\235\\276\"\n",
       "  }\n",
       "  initializer {\n",
       "    dims: 16\n",
       "    dims: 16\n",
       "    data_type: 1\n",
       "    name: \"onnx::MatMul_59\"\n",
       "    raw_data: \"\\031C\\264=\\033\\225\\220>\\366\\245\\r>\\247\\276/\\276\\217\\355H>p\\261\\230\\275\\271k\\215>\\3259\\223\\275\\2474\\345<t\\203Q\\275\\243\\315\\275<}\\313~>\\207h\\t=x\\253\\003\\274jp\\316<|\\225\\220=\\232\\021\\020\\276\\260l\\355\\275\\331<W\\276\\244\\t#\\276Y\\304\\035=\\377\\257\\237<\\'\\347\\273<\\353\\253\\207\\276\\'\\215\\237\\275\\016\\266\\252\\2756P:\\275!\\265\\n\\276\\260m\\362=P\\'B\\275\\203OG\\275$V\\304=1\\345\\036\\276\\001\\014m\\276$\\035\\276=\\2668\\302\\275\\310Kd\\276\\250\\327\\216\\273\\027\\252\\302\\276o\\367\\264>b\\370}\\275\\237\\365\\376\\275Q}$>\\016\\257\\237\\276Tg8\\276\\213k\\252:\\303\\205l>F\\231e\\276\\270\\002{>\\202\\003\\013>\\007\\211\\343\\275\\266g\\225\\276\\243\\033\\234>W\\312w\\276\\263\\353\\375=1\\306+\\275\\204A\\212>\\354S\\013\\276\\'6\\213=\\2431\\025>e\\254\\004=n\\320\\240>\\031\\356p\\276\\251\\301\\245\\275W\\277U>\\315=n=\\270\\277*\\276\\336D\\216=\\013\\265K=z<\\257\\276\\332ev>\\220J\\225\\276_\\316\\347=d\\206s>\\301-\\247=92\\234=9\\006\\231>{\\252\\232>\\207\\362\\370\\275\\\\\\274A>V\\005Z>\\030\\375\\327=\\322\\033\\302\\275\\362\\333\\r\\276\\024\\013\\236>F\\260I\\276B\\006c\\270\\037\\234_=\\324\\213\\247>y\\251\\376=C\\351\\232;\\311\\315\\216>\\265KQ\\275\\256\\025\\207>\\r\\010\\304\\275\\316\\231\\241=\\221\\330\\247>\\374%\\311\\275\\202\\n\\232=\\340\\375\\227\\276+z{>wi\\227\\276\\250\\247h=\\014\\221\\022\\275~,\\223=2\\010\\234>\\207\\217\\203=p\\rq<\\\"\\364h=\\255\\031J>\\360t\\224\\276\\261C\\013\\276\\210\\270\\023>\\213\\375\\220=ob-\\276\\254u\\020\\276\\315\\241\\274=\\326\\001Y\\276\\227\\362T=\\342\\354\\376\\275\\317\\024O>\\351\\326\\000>\\333\\004\\202<\\245_\\356\\275\\232\\353\\356\\275k3\\202>.\\305\\256\\2737\\024%>\\313\\356\\311=\\307(\\356\\274P\\030\\210>\\210[\\225>\\251c\\021\\275\\265N\\216>\\004(\\201\\276\\251lM>\\207\\323\\214\\276\\365\\242\\243\\276D\\005\\225=~T@\\275\\\\X\\031\\276\\363=\\217\\276\\357\\271\\246>\\307u\\227=\\212X*\\276\\231\\226n\\275\\236/\\262=\\371\\311|>X\\tr\\275\\341s6>\\246\\277\\371=4L\\016\\276\\225A\\256\\276h(\\357\\275e!\\303\\275\\237\\210\\205=\\222\\331\\213\\276\\311\\311\\321\\275{\\245\\273\\275^o\\353=@\\241\\253\\275\\331H\\271=\\351\\240%>M\\335\\300=H\\372f=\\374\\3325>\\212Z\\202\\276\\237\\353\\321\\273<$\\362\\275,\\006k\\275\\251\\366\\350\\273\\2367\\366\\275\\254e\\231\\2759k|\\275k\\320l>4\\234>\\276\\300w\\341<\\3608\\261>\\254\\307\\257\\2769\\364\\037\\276\\016M\\350=\\335\\007\\014<*\\231\\003>\\265D\\001\\276\\326\\365\\242=\\247\\2107>\\365\\224\\006\\276\\034n\\326>\\345)\\222=\\365\\030\\205<\\230\\326\\260\\276\\276\\2240>-1x=~\\025\\332\\275O\\003\\\"\\276PsQ\\276\\336\\202\\000=:\\226\\207\\275\\335\\206(\\276\\212i\\177>\\024\\311\\021>\\275\\246K\\275\\316g\\373=\\254\\270\\317\\275IG\\346\\274E\\007+\\275/\\251O=m\\321\\202\\276\\222\\264\\305=.\\311\\007>6\\306a\\276\\206\\344!\\276\\021\\366\\216>\\250\\034\\325\\275u\\2562\\274#T\\205\\275\\217\\222}>\\330\\373\\300=\\351\\316\\325\\275\\302\\022(>\\272F\\231>\\205Sg>\\336\\'6>\\n\\257j>\\366WS>VB,>\\215E\\232\\274JT\\341\\275\\266u\\334\\273\\275I\\014>R\\352\\215>p\\017u\\276\\221\\030\\276\\275j\\360.>\\035\\373y\\275y\\324s>\\023\\322[>]\\330\\272\\273Y\\347P\\276\\025\\237j>\\340\\326\\343=\\262%\\367=\\247D\\224\\276\\257\\306\\'\\276\\323\\303\\356\\273r\\036\\205\\275\\205\\314\\353=0\\255\\336\\275HI\\363<\\254\\246K\\275k\\265\\316\\274f]\\232>\\003I\\244=<}\\177>\\362\\253\\221=z8\\241>\"\n",
       "  }\n",
       "  initializer {\n",
       "    dims: 16\n",
       "    dims: 1\n",
       "    data_type: 1\n",
       "    name: \"onnx::MatMul_60\"\n",
       "    raw_data: \"\\355)h\\276H\\364\\312\\276\\224m\\221>`\\342\\235>\\306\\037J\\276\\261\\031\\242>\\307\\310\\244\\276\\003\\023\\240>\\026\\236\\275\\276\\327m\\315\\276\\264;\\316<=\\254\\242\\276\\356\\177\\253\\276\\236\\327\\215\\276Y{\\243>X n\\276\"\n",
       "  }\n",
       "  input {\n",
       "    name: \"model_batch\"\n",
       "    type {\n",
       "      tensor_type {\n",
       "        elem_type: 1\n",
       "        shape {\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "          dim {\n",
       "            dim_value: 10000\n",
       "          }\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  input {\n",
       "    name: \"onnx::MatMul_3\"\n",
       "    type {\n",
       "      tensor_type {\n",
       "        elem_type: 1\n",
       "        shape {\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "          dim {\n",
       "            dim_value: 10000\n",
       "          }\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  output {\n",
       "    name: \"52\"\n",
       "    type {\n",
       "      tensor_type {\n",
       "        elem_type: 1\n",
       "        shape {\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "          dim {\n",
       "            dim_value: 10000\n",
       "          }\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = onnx.load(\"./ckpts/burgers_1d_v1.onnx\")\n",
    "d(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph main_graph (\n",
      "  %model_batch[FLOAT, 1x10000x1]\n",
      "  %onnx::MatMul_3[FLOAT, 1x10000x1]\n",
      ") initializers (\n",
      "  %layers.0.partial_model.branched_linear_block_xyz.0.0.bias[FLOAT, 16]\n",
      "  %layers.0.partial_model.linear_block_t.0.bias[FLOAT, 16]\n",
      "  %layers.0.partial_model.out_linear_block.bias[FLOAT, 16]\n",
      "  %layers.1.partial_model.linear_block.0.0.bias[FLOAT, 16]\n",
      "  %layers.1.partial_model.linear_block.1.0.bias[FLOAT, 16]\n",
      "  %layers.1.partial_model.linear_block.2.0.bias[FLOAT, 16]\n",
      "  %layers.1.partial_model.linear_block.3.0.bias[FLOAT, 16]\n",
      "  %layers.1.partial_model.out_block.bias[FLOAT, 1]\n",
      "  %onnx::MatMul_53[FLOAT, 1x16]\n",
      "  %onnx::MatMul_54[FLOAT, 1x16]\n",
      "  %onnx::MatMul_55[FLOAT, 32x16]\n",
      "  %onnx::MatMul_56[FLOAT, 16x16]\n",
      "  %onnx::MatMul_57[FLOAT, 16x16]\n",
      "  %onnx::MatMul_58[FLOAT, 16x16]\n",
      "  %onnx::MatMul_59[FLOAT, 16x16]\n",
      "  %onnx::MatMul_60[FLOAT, 16x1]\n",
      ") {\n",
      "  %/layers/layers.0/partial_model/branched_linear_block_xyz.0/branched_linear_block_xyz.0.0/MatMul_output_0 = MatMul(%model_batch, %onnx::MatMul_53)\n",
      "  %/layers/layers.0/partial_model/branched_linear_block_xyz.0/branched_linear_block_xyz.0.0/Add_output_0 = Add(%layers.0.partial_model.branched_linear_block_xyz.0.0.bias, %/layers/layers.0/partial_model/branched_linear_block_xyz.0/branched_linear_block_xyz.0.0/MatMul_output_0)\n",
      "  %/layers/layers.0/partial_model/branched_linear_block_xyz.0/branched_linear_block_xyz.0.1/Tanh_output_0 = Tanh(%/layers/layers.0/partial_model/branched_linear_block_xyz.0/branched_linear_block_xyz.0.0/Add_output_0)\n",
      "  %/layers/layers.0/partial_model/Concat_output_0 = Concat[axis = 1](%/layers/layers.0/partial_model/branched_linear_block_xyz.0/branched_linear_block_xyz.0.1/Tanh_output_0)\n",
      "  %/layers/layers.0/partial_model/linear_block_t/linear_block_t.0/MatMul_output_0 = MatMul(%onnx::MatMul_3, %onnx::MatMul_54)\n",
      "  %/layers/layers.0/partial_model/linear_block_t/linear_block_t.0/Add_output_0 = Add(%layers.0.partial_model.linear_block_t.0.bias, %/layers/layers.0/partial_model/linear_block_t/linear_block_t.0/MatMul_output_0)\n",
      "  %/layers/layers.0/partial_model/linear_block_t/linear_block_t.1/Tanh_output_0 = Tanh(%/layers/layers.0/partial_model/linear_block_t/linear_block_t.0/Add_output_0)\n",
      "  %/layers/layers.0/partial_model/Concat_1_output_0 = Concat[axis = -1](%/layers/layers.0/partial_model/Concat_output_0, %/layers/layers.0/partial_model/linear_block_t/linear_block_t.1/Tanh_output_0)\n",
      "  %/layers/layers.0/partial_model/out_linear_block/MatMul_output_0 = MatMul(%/layers/layers.0/partial_model/Concat_1_output_0, %onnx::MatMul_55)\n",
      "  %/layers/layers.0/partial_model/out_linear_block/Add_output_0 = Add(%layers.0.partial_model.out_linear_block.bias, %/layers/layers.0/partial_model/out_linear_block/MatMul_output_0)\n",
      "  %/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.0/linear_block.0.0/MatMul_output_0 = MatMul(%/layers/layers.0/partial_model/out_linear_block/Add_output_0, %onnx::MatMul_56)\n",
      "  %/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.0/linear_block.0.0/Add_output_0 = Add(%layers.1.partial_model.linear_block.0.0.bias, %/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.0/linear_block.0.0/MatMul_output_0)\n",
      "  %/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.0/linear_block.0.2/Tanh_output_0 = Tanh(%/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.0/linear_block.0.0/Add_output_0)\n",
      "  %/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.1/linear_block.1.0/MatMul_output_0 = MatMul(%/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.0/linear_block.0.2/Tanh_output_0, %onnx::MatMul_57)\n",
      "  %/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.1/linear_block.1.0/Add_output_0 = Add(%layers.1.partial_model.linear_block.1.0.bias, %/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.1/linear_block.1.0/MatMul_output_0)\n",
      "  %/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.1/linear_block.1.2/Tanh_output_0 = Tanh(%/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.1/linear_block.1.0/Add_output_0)\n",
      "  %/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.2/linear_block.2.0/MatMul_output_0 = MatMul(%/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.1/linear_block.1.2/Tanh_output_0, %onnx::MatMul_58)\n",
      "  %/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.2/linear_block.2.0/Add_output_0 = Add(%layers.1.partial_model.linear_block.2.0.bias, %/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.2/linear_block.2.0/MatMul_output_0)\n",
      "  %/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.2/linear_block.2.2/Tanh_output_0 = Tanh(%/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.2/linear_block.2.0/Add_output_0)\n",
      "  %/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.3/linear_block.3.0/MatMul_output_0 = MatMul(%/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.2/linear_block.2.2/Tanh_output_0, %onnx::MatMul_59)\n",
      "  %/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.3/linear_block.3.0/Add_output_0 = Add(%layers.1.partial_model.linear_block.3.0.bias, %/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.3/linear_block.3.0/MatMul_output_0)\n",
      "  %/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.3/linear_block.3.2/Tanh_output_0 = Tanh(%/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.3/linear_block.3.0/Add_output_0)\n",
      "  %/layers/layers.1/partial_model/cls_layers/out_block/MatMul_output_0 = MatMul(%/layers/layers.1/partial_model/cls_layers/linear_block/linear_block.3/linear_block.3.2/Tanh_output_0, %onnx::MatMul_60)\n",
      "  %/layers/layers.1/partial_model/cls_layers/out_block/Add_output_0 = Add(%layers.1.partial_model.out_block.bias, %/layers/layers.1/partial_model/cls_layers/out_block/MatMul_output_0)\n",
      "  %52 = Tanh(%/layers/layers.1/partial_model/cls_layers/out_block/Add_output_0)\n",
      "  return %52\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(onnx.helper.printable_graph(model.graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_session = ort.InferenceSession(\"./ckpts/burgers_1d_v1.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_batch'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(ort_session.get_inputs()[0].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor: torch.Tensor) -> np.ndarray:\n",
    "    return tensor.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Iterable of <class 'numpy.ndarray'> should be given as array for input 'model_batch'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[159], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mort_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mort_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mCoords\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoord\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcoord\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mort_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:220\u001b[0m, in \u001b[0;36mSession.run\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    218\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Iterable of <class 'numpy.ndarray'> should be given as array for input 'model_batch'."
     ]
    }
   ],
   "source": [
    "outputs = ort_session.run(\n",
    "    output_names=None, \n",
    "    input_feed={\n",
    "        ort_session.get_inputs()[0].name: Coords(*[to_numpy(coord) for coord in sample.coords]), \n",
    "        ort_session.get_inputs()[1].name: to_numpy(sample.time)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ModelProto' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimeit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel(*sample)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2480\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2478\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2480\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2484\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/magics/execution.py:1185\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m   1184\u001b[0m     number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m index\n\u001b[0;32m-> 1185\u001b[0m     time_number \u001b[38;5;241m=\u001b[39m \u001b[43mtimer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time_number \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m:\n\u001b[1;32m   1187\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/magics/execution.py:173\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    171\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<magic-timeit>:1\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ModelProto' object is not callable"
     ]
    }
   ],
   "source": [
    "%timeit model(*sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
